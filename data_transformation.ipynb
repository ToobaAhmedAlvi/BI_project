{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f13da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading source tables...\n",
      "‚ùå Error loading DIM_DATE: 000904 (42000): SQL compilation error: error line 1 at position 135\n",
      "invalid identifier 'MONTH_NAME'\n",
      "‚úÖ DIM_INVOICE loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from snowflake.snowpark import Session\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Snowflake connection configuration\n",
    "snowflake_params = {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"role\": os.getenv(\"SNOWFLAKE_ROLE\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": \"ERD_SCHEMA_CLEANED\"\n",
    "}\n",
    "final_schema = os.getenv(\"SNOWFLAKE_STAR_SCHEMA\")\n",
    "\n",
    "# Initialize session\n",
    "session = Session.builder.configs(snowflake_params).create()\n",
    "\n",
    "def set_schema(schema):\n",
    "    session.sql(f'USE SCHEMA \"{snowflake_params[\"database\"]}\".\"{schema}\"').collect()\n",
    "\n",
    "# Load source tables\n",
    "print(\"üîÑ Loading source tables...\")\n",
    "df_customer = session.table(\"CUSTOMER\").to_pandas()\n",
    "df_employee = session.table(\"EMPLOYEE\").to_pandas()\n",
    "df_artist = session.table(\"ARTIST\").to_pandas()\n",
    "df_album = session.table(\"ALBUM\").to_pandas()\n",
    "df_invoice = session.table(\"INVOICE\").to_pandas()\n",
    "df_invoiceline = session.table(\"INVOICELINE\").to_pandas()\n",
    "df_track = session.table(\"TRACK\").to_pandas()\n",
    "df_playlisttrack = session.table(\"PLAYLISTTRACK\").to_pandas()\n",
    "df_genre = session.table(\"GENRE\").to_pandas()\n",
    "df_mediatype = session.table(\"MEDIATYPE\").to_pandas()\n",
    "df_playlist = session.table(\"PLAYLIST\").to_pandas()\n",
    "\n",
    "# Ensure that columns exist and are correctly typed\n",
    "def ensure_int_key(df, col):\n",
    "    \"\"\"Ensure that a column exists and is converted to an integer, handling errors.\"\"\"\n",
    "    if col in df.columns:\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while converting {col} to int: {e}\")\n",
    "    else:\n",
    "        print(f\"Column {col} is missing in the DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# Dimension creation functions\n",
    "def create_dim_date(df_invoice):\n",
    "    df_date = df_invoice[['INVOICEDATE']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df_date['DATE'] = pd.to_datetime(df_date['INVOICEDATE']).dt.date\n",
    "    df_date['DAY'] = pd.to_datetime(df_date['DATE']).dt.day\n",
    "    df_date['WEEK_DAY'] = pd.to_datetime(df_date['DATE']).dt.strftime('%A')\n",
    "    df_date['MONTH_NAME'] = pd.to_datetime(df_date['DATE']).dt.strftime('%B')\n",
    "    df_date['MONTH_NUMBER'] = pd.to_datetime(df_date['DATE']).dt.month\n",
    "    df_date['QUARTER'] = pd.to_datetime(df_date['DATE']).dt.quarter\n",
    "    df_date['YEAR'] = pd.to_datetime(df_date['DATE']).dt.year\n",
    "    df_date['IS_HOLIDAY'] = False  # Set holiday logic if necessary\n",
    "    df_date['IS_WEEKEND'] = df_date['WEEK_DAY'].isin(['Saturday', 'Sunday'])\n",
    "    df_date['DATE_ID'] = range(1, len(df_date) + 1)  # Create surrogate key\n",
    "    return df_date[['DATE_ID', 'DATE', 'DAY', 'WEEK_DAY', 'IS_HOLIDAY', 'IS_WEEKEND', 'MONTH_NAME', 'MONTH_NUMBER', 'QUARTER', 'YEAR']]\n",
    "\n",
    "def create_dim_location(df_customer):\n",
    "    df_location = df_customer[['CITY', 'STATE', 'COUNTRY', 'POSTALCODE']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df_location['LOCATION_ID'] = range(1, len(df_location) + 1)  # Create surrogate key\n",
    "    return df_location[['LOCATION_ID', 'CITY', 'STATE', 'COUNTRY', 'POSTALCODE']]\n",
    "\n",
    "def create_dim_album_artist(df_album, df_artist):\n",
    "    # Check if 'ARTISTID' exists in df_album\n",
    "    if 'ARTISTID' not in df_album.columns:\n",
    "        print(\" 'ARTISTID' column is missing in df_album. Checking the available columns...\")\n",
    "        print(df_album.columns)  # Output the column names for inspection\n",
    "        # Attempt to merge with df_track if ARTISTID is in df_track\n",
    "        if 'ARTISTID' in df_track.columns:\n",
    "            print(\"'ARTISTID' found in df_track, merging with df_track...\")\n",
    "            df_album = df_album.merge(df_track[['ALBUMID', 'ARTISTID']], on='ALBUMID', how='left')\n",
    "        else:\n",
    "            print(\"'ARTISTID' column not found in either df_album or df_track.\")\n",
    "            return None\n",
    "\n",
    "    # Proceed with merging df_album and df_artist if 'ARTISTID' is found\n",
    "    df_album_artist = df_album[['ALBUMID', 'TITLE', 'ARTISTID']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Ensure 'ARTISTID' exists in df_album (and in df_artist as well)\n",
    "    if 'ARTISTID' in df_album.columns and 'ARTISTID' in df_artist.columns:\n",
    "        df_album_artist = df_album_artist.merge(df_artist[['ARTISTID', 'NAME']], left_on='ARTISTID', right_on='ARTISTID', how='left')\n",
    "    else:\n",
    "        print(\"'ARTISTID' column not found in one of the DataFrames. Cannot merge.\")\n",
    "\n",
    "    # Create surrogate key for the dimension\n",
    "    df_album_artist['ALBUM_ARTIST_ID'] = range(1, len(df_album_artist) + 1)\n",
    "    \n",
    "    # Return the cleaned and merged DataFrame\n",
    "    return df_album_artist[['ALBUM_ARTIST_ID', 'ALBUMID', 'TITLE', 'ARTISTID', 'NAME']]\n",
    "\n",
    "def create_dim_track(df_track, df_genre, df_mediatype):\n",
    "    # Merge df_track with df_genre\n",
    "    if 'GENREID' in df_track.columns and 'GENREID' in df_genre.columns:\n",
    "        df_track = df_track.merge(df_genre[['GENREID', 'NAME']], left_on='GENREID', right_on='GENREID', how='left')\n",
    "        df_track.rename(columns={'NAME': 'GENRE_NAME'}, inplace=True)  # Rename 'NAME' to 'GENRE_NAME'\n",
    "    else:\n",
    "        print(\" 'GENREID' column missing in either df_track or df_genre. Cannot merge.\")\n",
    "\n",
    "    # Merge df_track with df_mediatype\n",
    "    if 'MEDIATYPEID' in df_track.columns and 'MEDIATYPEID' in df_mediatype.columns:\n",
    "        df_track = df_track.merge(df_mediatype[['MEDIATYPEID', 'NAME']], left_on='MEDIATYPEID', right_on='MEDIATYPEID', how='left')\n",
    "        df_track.rename(columns={'NAME': 'MEDIA_TYPE_NAME'}, inplace=True)  # Rename 'NAME' to 'MEDIA_TYPE_NAME'\n",
    "    else:\n",
    "        print(\"'MEDIATYPEID' column missing in either df_track or df_mediatype. Cannot merge.\")\n",
    "\n",
    "    # Create surrogate key\n",
    "    df_track['TRACK_ID'] = range(1, len(df_track) + 1)  # Surrogate key\n",
    "\n",
    "    # Ensure that the selected columns exist before returning\n",
    "    required_columns = ['TRACK_ID', 'TRACKID', 'NAME', 'ALBUMID', 'MEDIATYPEID', 'GENREID', 'GENRE_NAME', 'MEDIA_TYPE_NAME']\n",
    "    \n",
    "    missing_columns = [col for col in required_columns if col not in df_track.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Missing columns: {missing_columns}\")\n",
    "\n",
    "    # Return the cleaned and merged DataFrame with only the required columns\n",
    "    return df_track[['TRACK_ID', 'TRACKID', 'NAME', 'ALBUMID', 'MEDIATYPEID', 'GENREID', 'GENRE_NAME', 'MEDIA_TYPE_NAME']]\n",
    "\n",
    "def create_dim_playlist_track(df_playlisttrack, df_playlist):\n",
    "    df_playlist_track = df_playlisttrack[['PLAYLISTID', 'TRACKID']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df_playlist_track = df_playlist_track.merge(df_playlist[['PLAYLISTID', 'NAME']], left_on='PLAYLISTID', right_on='PLAYLISTID', how='left')\n",
    "    df_playlist_track['PLAYLIST_TRACK_ID'] = range(1, len(df_playlist_track) + 1)  # Create surrogate key\n",
    "    return df_playlist_track[['PLAYLIST_TRACK_ID', 'PLAYLISTID', 'TRACKID', 'NAME']]\n",
    "\n",
    "def create_dim_employee(df_employee):\n",
    "    df_employee = df_employee[['EMPLOYEEID', 'LASTNAME', 'FIRSTNAME', 'TITLE', 'REPORTSTO', 'BIRTHDATE', 'HIREDATE', 'ADDRESS', 'PHONE', 'FAX', 'EMAIL']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df_employee['EMPLOYEE_ID'] = range(1, len(df_employee) + 1)  # Create surrogate key\n",
    "    return df_employee[['EMPLOYEE_ID', 'EMPLOYEEID', 'LASTNAME', 'FIRSTNAME', 'TITLE', 'REPORTSTO', 'BIRTHDATE', 'HIREDATE', 'ADDRESS', 'PHONE', 'FAX', 'EMAIL']]\n",
    "# Dimension creation function for DimDate without WEEK_DAY\n",
    "def create_dim_date(df_invoice):\n",
    "    # Extract unique invoice dates\n",
    "    df_date = df_invoice[['INVOICEDATE']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Convert INVOICEDATE to datetime format\n",
    "    df_date['DATE'] = pd.to_datetime(df_date['INVOICEDATE']).dt.date\n",
    "    df_date['DAY'] = pd.to_datetime(df_date['DATE']).dt.day\n",
    "    df_date['MONTH_NAME'] = pd.to_datetime(df_date['DATE']).dt.strftime('%B')\n",
    "    df_date['MONTH_NUMBER'] = pd.to_datetime(df_date['DATE']).dt.month\n",
    "    df_date['QUARTER'] = pd.to_datetime(df_date['DATE']).dt.quarter\n",
    "    df_date['YEAR'] = pd.to_datetime(df_date['DATE']).dt.year\n",
    "    df_date['IS_HOLIDAY'] = False  # Set to False, modify logic for actual holidays\n",
    "    df_date['IS_WEEKEND'] = df_date['MONTH_NAME'].isin(['Saturday', 'Sunday'])\n",
    "    \n",
    "    # Surrogate key: DATE_ID\n",
    "    df_date['DATE_ID'] = range(1, len(df_date) + 1)\n",
    "    \n",
    "    # Ensure all column names are in uppercase for consistency with Snowflake\n",
    "    df_date.columns = df_date.columns.str.upper()\n",
    "\n",
    "    # Return the relevant columns without WEEK_DAY\n",
    "    return df_date[['DATE_ID', 'DATE', 'DAY', 'IS_HOLIDAY', 'IS_WEEKEND', 'MONTH_NAME', 'MONTH_NUMBER', 'QUARTER', 'YEAR']]\n",
    "\n",
    "# Dimension creation function for DimInvoice\n",
    "def create_dim_invoice(df_invoice):\n",
    "    # Select the necessary columns and remove duplicates\n",
    "    df_invoice = df_invoice[['INVOICEID', 'CUSTOMERID', 'INVOICEDATE', 'TOTAL']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # Convert INVOICEDATE to datetime format\n",
    "    df_invoice['INVOICEDATE'] = pd.to_datetime(df_invoice['INVOICEDATE']).dt.date\n",
    "    \n",
    "    # Surrogate key for DimInvoice\n",
    "    df_invoice['INVOICE_ID'] = range(1, len(df_invoice) + 1)\n",
    "    \n",
    "    # Ensure all column names are in uppercase for consistency with Snowflake\n",
    "    df_invoice.columns = df_invoice.columns.str.upper()\n",
    "    \n",
    "    # Return the relevant columns for DimInvoice\n",
    "    return df_invoice[['INVOICE_ID', 'INVOICEID', 'CUSTOMERID', 'INVOICEDATE', 'TOTAL']]\n",
    "\n",
    "\n",
    "def create_dim_customer(df_customer):\n",
    "    df_customer = df_customer[['CUSTOMERID', 'FIRSTNAME', 'LASTNAME', 'COMPANY', 'ADDRESS', 'PHONE', 'FAX', 'EMAIL', 'SUPPORTREPID']].dropna().drop_duplicates().reset_index(drop=True)\n",
    "    df_customer['CUSTOMER_ID'] = range(1, len(df_customer) + 1)  # Create surrogate key\n",
    "    return df_customer[['CUSTOMER_ID', 'CUSTOMERID', 'FIRSTNAME', 'LASTNAME', 'COMPANY', 'ADDRESS', 'PHONE', 'FAX', 'EMAIL', 'SUPPORTREPID']]\n",
    "\n",
    "# Fact table creation logic\n",
    "def create_fact_sales(df_invoiceline, df_invoice, df_track, df_album, df_artist,\n",
    "                      df_customer, df_employee, df_playlisttrack, dim_location):\n",
    "    df_invoiceline.columns = df_invoiceline.columns.str.upper()\n",
    "    df_invoice.columns = df_invoice.columns.str.upper()\n",
    "    df_track.columns = df_track.columns.str.upper()\n",
    "    df_album.columns = df_album.columns.str.upper()\n",
    "    df_artist.columns = df_artist.columns.str.upper()\n",
    "    df_customer.columns = df_customer.columns.str.upper()\n",
    "    df_employee.columns = df_employee.columns.str.upper()\n",
    "\n",
    "    df_customer.rename(columns={\n",
    "        'BILLINGCITY': 'CITY',\n",
    "        'BILLINGSTATE': 'STATE',\n",
    "        'BILLINGCOUNTRY': 'COUNTRY',\n",
    "        'BILLINGPOSTALCODE': 'POSTALCODE'\n",
    "    }, inplace=True)\n",
    "\n",
    "    df_invoice.rename(columns={'INVOICEDATE': 'INVOICE_DATE', 'UNITPRICE': 'UNIT_PRICE'}, inplace=True)\n",
    "    invoice_subset = df_invoice.drop(columns=['INVOICEDATE'], errors='ignore')\n",
    "    fact = df_invoiceline.merge(invoice_subset, on='INVOICEID', how='left', suffixes=('', '_inv'))\n",
    "\n",
    "    # Resolve duplicate 'UNITPRICE'\n",
    "    if 'UNITPRICE_y' in fact.columns:\n",
    "        fact['UNIT_PRICE'] = fact['UNITPRICE_y']  \n",
    "        fact = fact.drop(columns=['UNITPRICE_y'])\n",
    "\n",
    "    if 'UNITPRICE_x' in fact.columns:\n",
    "        fact['UNIT_PRICE'] = fact['UNITPRICE_x']\n",
    "        fact = fact.drop(columns=['UNITPRICE_x'])\n",
    "\n",
    "    fact = fact.merge(df_customer, on='CUSTOMERID', how='left')\n",
    "    if 'SUPPORTREPID' in df_customer.columns:\n",
    "        fact = fact.merge(df_employee, left_on='SUPPORTREPID', right_on='EMPLOYEEID', how='left')\n",
    "\n",
    "    fact = fact.merge(df_track, on='TRACKID', how='left')\n",
    "    fact = fact.merge(df_album, on='ALBUMID', how='left')\n",
    "    fact = fact.merge(df_artist, on='ARTISTID', how='left')\n",
    "\n",
    "    location_keys = ['CITY', 'STATE', 'COUNTRY', 'POSTALCODE']\n",
    "    invoice_address_keys = ['BILLINGCITY', 'BILLINGSTATE', 'BILLINGCOUNTRY', 'BILLINGPOSTALCODE']\n",
    "    if all(col in fact.columns for col in location_keys):\n",
    "        fact = fact.merge(dim_location, left_on=location_keys, right_on=location_keys, how='left')\n",
    "    elif all(col in fact.columns for col in invoice_address_keys):\n",
    "        fact = fact.merge(dim_location, left_on=invoice_address_keys, right_on=location_keys, how='left')\n",
    "\n",
    "    if 'UNIT_PRICE' in fact.columns:\n",
    "        fact['EXTENDED_PRICE'] = fact['UNIT_PRICE'] * fact['QUANTITY']\n",
    "\n",
    "    rename_map = {\n",
    "        'INVOICELINEID': 'INVOICELINE_ID',\n",
    "        'INVOICEID': 'INVOICE_ID',\n",
    "        'INVOICE_DATE': 'INVOICE_DATE',\n",
    "        'TRACKID': 'TRACK_ID',\n",
    "        'CUSTOMERID': 'CUSTOMER_ID',\n",
    "        'UNIT_PRICE': 'UNIT_PRICE',\n",
    "        'QUANTITY': 'QUANTITY',\n",
    "        'EXTENDED_PRICE': 'EXTENDED_PRICE'\n",
    "    }\n",
    "    if 'SUPPORTREPID' in fact.columns:\n",
    "        rename_map['SUPPORTREPID'] = 'EMPLOYEE_ID'\n",
    "\n",
    "    fact_sales = fact.rename(columns=rename_map)\n",
    "\n",
    "    columns_to_keep = [\n",
    "        'INVOICELINE_ID', 'LOCATION_ID', 'INVOICE_ID', 'TRACK_ID', 'CUSTOMER_ID',\n",
    "        'EMPLOYEE_ID', 'MEDIATYPE_ID', 'INVOICE_DATE', 'UNIT_PRICE', 'QUANTITY',\n",
    "        'TOTAL_AMOUNT', 'PLAYLIST_ID', 'ALBUM_ID', 'ARTIST_ID', 'MILLISECONDS', 'BYTES'\n",
    "    ]\n",
    "    fact_sales = fact_sales[columns_to_keep]\n",
    "\n",
    "    return fact_sales.reset_index(drop=True)\n",
    "\n",
    "# Dimension creation functions called\n",
    "dim_date = create_dim_date(df_invoice)\n",
    "dim_location = create_dim_location(df_customer)\n",
    "dim_album_artist = create_dim_album_artist(df_album, df_artist)\n",
    "dim_track = create_dim_track(df_track, df_genre, df_mediatype)\n",
    "dim_playlist_track = create_dim_playlist_track(df_playlisttrack, df_playlist)\n",
    "dim_employee = create_dim_employee(df_employee)\n",
    "dim_customer = create_dim_customer(df_customer)\n",
    "dim_invoice = create_dim_invoice(df_invoice)\n",
    "fact_sales = create_fact_sales(df_invoiceline, df_invoice, df_track, df_album, df_artist,\n",
    "                               df_customer, df_employee, df_playlisttrack, dim_location)\n",
    "\n",
    "# Switch to final schema\n",
    "set_schema(final_schema)\n",
    "\n",
    "print(\"‚úÖ All dimensions and facts loaded into ERD_SCHEMA_STAR successfully.\")\n",
    "\n",
    "# Create the dimensions\n",
    "# Load DimDate into Snowflake\n",
    "try:\n",
    "    session.write_pandas(dim_date, \"DIM_DATE\", overwrite=True)\n",
    "    print(\"‚úÖ DIM_DATE loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading DIM_DATE: {e}\")\n",
    "\n",
    "# Load DimInvoice into Snowflake\n",
    "try:\n",
    "    session.write_pandas(dim_invoice, \"DIM_INVOICE\", overwrite=True)\n",
    "    print(\"‚úÖ DIM_INVOICE loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading DIM_INVOICE: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
